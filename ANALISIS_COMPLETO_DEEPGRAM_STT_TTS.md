# AN√ÅLISIS COMPLETO: PROBLEMA DEEPGRAM STT/TTS
## Sistema Galaxy - Llamada Conversacional en Tiempo Real

---

## 1. AN√ÅLISIS DEL SISTEMA ACTUAL

### 1.1 Arquitectura del Proyecto

#### **Estructura de Archivos:**
```
GUESTVALENCIAPWA/
‚îú‚îÄ‚îÄ server.js              # Servidor HTTP (puerto 4040) - API REST
‚îú‚îÄ‚îÄ server-websocket.js     # Servidor WebSocket (puerto 4041) - Llamada conversacional
‚îú‚îÄ‚îÄ index.html             # Cliente PWA con widget de Sandra
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ api-gateway.js     # Sistema Galaxy original (referencia)
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sandra-gateway.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sandra-widget-integrated.js
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îî‚îÄ‚îÄ .env                   # Variables de entorno (API keys)
```

### 1.2 Flujo Actual de Llamada Conversacional

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CLIENTE (index.html)                                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Usuario hace clic en "Llamada conversacional"           ‚îÇ
‚îÇ 2. startConversationalCall()                                ‚îÇ
‚îÇ 3. WebSocket.connect('ws://localhost:4041')                 ‚îÇ
‚îÇ 4. navigator.mediaDevices.getUserMedia({ audio: true })     ‚îÇ
‚îÇ 5. MediaRecorder (audio/webm;codecs=opus)                  ‚îÇ
‚îÇ 6. mediaRecorder.start(100) - chunks cada 100ms             ‚îÇ
‚îÇ 7. mediaRecorder.onstop()                                   ‚îÇ
‚îÇ 8. Blob ‚Üí FileReader ‚Üí base64                               ‚îÇ
‚îÇ 9. ws.send({ type: 'audio', audio: base64Audio })           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SERVIDOR WEBSOCKET (server-websocket.js)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. ws.on('message') ‚Üí data.type === 'audio'                ‚îÇ
‚îÇ 2. transcribeAudio(data.audio)                              ‚îÇ
‚îÇ    ‚îú‚îÄ Buffer.from(base64, 'base64')                         ‚îÇ
‚îÇ    ‚îú‚îÄ https.request ‚Üí api.deepgram.com/v1/listen           ‚îÇ
‚îÇ    ‚îî‚îÄ Parse JSON ‚Üí transcript                               ‚îÇ
‚îÇ 3. generateStreamingResponse(userText, history)             ‚îÇ
‚îÇ    ‚îî‚îÄ callGeminiStreaming() / callGPT4oStreaming()          ‚îÇ
‚îÇ 4. generateTTS(response)                                    ‚îÇ
‚îÇ    ‚îî‚îÄ Cartesia API ‚Üí audio base64                           ‚îÇ
‚îÇ 5. ws.send({ type: 'text', text: response })               ‚îÇ
‚îÇ 6. ws.send({ type: 'audio', audio: audioBase64 })          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CLIENTE (index.html)                                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. ws.onmessage ‚Üí data.type === 'text'                      ‚îÇ
‚îÇ 2. addMessage(data.text, 'bot')                             ‚îÇ
‚îÇ 3. ws.onmessage ‚Üí data.type === 'audio'                     ‚îÇ
‚îÇ 4. playAudioResponse(data.audio)                            ‚îÇ
‚îÇ 5. Loop: volver a capturar audio                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.3 Sistema Galaxy Original

#### **Componentes del Sistema Galaxy:**
- **AIOrchestrator**: Clase principal que gestiona IA (Gemini, OpenAI)
- **TTS (Cartesia)**: Implementado y funcionando
- **STT (Deepgram)**: Referenciado pero no completamente implementado en el original
- **Endpoints REST**: `/api/sandra/chat`, `/api/sandra/voice`

#### **Diferencias con Implementaci√≥n Actual:**
- El sistema original NO ten√≠a llamada conversacional en tiempo real
- Solo ten√≠a TTS para respuestas de voz
- STT estaba referenciado pero no implementado para llamadas en tiempo real

---

## 2. DIAGN√ìSTICO DEL PROBLEMA ACTUAL

### 2.1 S√≠ntoma Principal

**Deepgram responde con HTTP 200 OK, pero devuelve transcript vac√≠o:**
```json
{
  "results": {
    "channels": [{
      "alternatives": [{
        "transcript": "",
        "confidence": 0,
        "words": [],
        "paragraphs": {
          "transcript": "\n",
          "paragraphs": []
        }
      }]
    }]
  }
}
```

### 2.2 An√°lisis del Flujo de Audio

#### **Cliente ‚Üí Servidor:**
1. **Captura**: `MediaRecorder` con `mimeType: 'audio/webm;codecs=opus'`
2. **Chunks**: Cada 100ms (muy cortos para Deepgram)
3. **Conversi√≥n**: `Blob` ‚Üí `FileReader.readAsDataURL()` ‚Üí base64
4. **Env√≠o**: WebSocket con `{ type: 'audio', audio: base64Audio }`

#### **Servidor ‚Üí Deepgram:**
1. **Decodificaci√≥n**: `Buffer.from(audioBase64, 'base64')`
2. **Request**: `POST /v1/listen?model=nova-2&language=es&punctuate=true&smart_format=true`
3. **Headers**: 
   - `Authorization: Token ${DEEPGRAM_API_KEY}`
   - `Content-Type: audio/webm`
   - `Content-Length: audioBuffer.length`
4. **Body**: Buffer raw del audio

### 2.3 Posibles Causas del Problema

#### **A) Formato de Audio**
- **Problema potencial**: Deepgram puede no reconocer correctamente `audio/webm;codecs=opus`
- **Soluci√≥n**: Especificar encoding en query params o convertir a formato m√°s compatible

#### **B) Tama√±o de Chunks**
- **Problema actual**: Chunks de 100ms son demasiado cortos
- **Deepgram m√≠nimo**: Requiere ~500ms-1s de audio para transcribir
- **Soluci√≥n**: Acumular chunks hasta tener m√≠nimo 1-2 segundos

#### **C) Calidad del Audio**
- **Problema potencial**: Audio puede estar silencioso o con ruido
- **Soluci√≥n**: Validar nivel de audio antes de enviar

#### **D) Configuraci√≥n de Deepgram**
- **Problema potencial**: Par√°metros de query string pueden ser incorrectos
- **Soluci√≥n**: Revisar documentaci√≥n y ajustar par√°metros

#### **E) Conversi√≥n Base64**
- **Problema potencial**: Prefijo `data:audio/webm;base64,` puede estar presente
- **Soluci√≥n**: Ya implementado (remover prefijo), pero verificar

---

## 3. AN√ÅLISIS DEL C√ìDIGO ACTUAL

### 3.1 Cliente (index.html) - Captura de Audio

**Ubicaci√≥n**: L√≠neas ~2104-2163

**Problemas identificados:**
1. ‚úÖ Chunks muy cortos (100ms) - **PROBLEMA CR√çTICO**
2. ‚úÖ Validaci√≥n de tama√±o m√≠nimo implementada
3. ‚úÖ Limpieza de prefijo base64 implementada
4. ‚ö†Ô∏è No hay validaci√≥n de nivel de audio (silence detection)

**C√≥digo actual:**
```javascript
mediaRecorder.start(100); // Chunks cada 100ms - MUY CORTO
```

### 3.2 Servidor (server-websocket.js) - Transcripci√≥n

**Ubicaci√≥n**: L√≠neas ~158-269

**Problemas identificados:**
1. ‚úÖ Manejo de transcript vac√≠o mejorado (resuelve con string vac√≠o)
2. ‚úÖ Logs detallados implementados
3. ‚ö†Ô∏è Query params pueden necesitar ajuste
4. ‚ö†Ô∏è No hay validaci√≥n de calidad de audio antes de enviar

**C√≥digo actual:**
```javascript
const queryParams = new URLSearchParams({
  model: 'nova-2',
  language: 'es',
  punctuate: 'true',
  smart_format: 'true'
});
```

### 3.3 TTS (Cartesia) - Generaci√≥n de Voz

**Ubicaci√≥n**: L√≠neas ~471-516

**Estado**: ‚úÖ Funcionando correctamente
- Formato: MP3, 24000 Hz
- API: Cartesia v2024-06-10
- Voice ID: Configurado desde .env

---

## 4. PLAN DE SOLUCI√ìN DETALLADO

### FASE 1: CORRECCI√ìN DEL STT (Deepgram)

#### **Paso 1.1: Acumular Chunks de Audio**
**Problema**: Chunks de 100ms son demasiado cortos para Deepgram
**Soluci√≥n**: Acumular chunks hasta tener m√≠nimo 1-2 segundos antes de enviar

**Implementaci√≥n:**
```javascript
// En index.html, startRealTimeCall()
let audioChunks = [];
let lastSendTime = Date.now();
const MIN_AUDIO_DURATION = 1500; // 1.5 segundos m√≠nimo

mediaRecorder.ondataavailable = (event) => {
  if (event.data.size > 0) {
    audioChunks.push(event.data);
    
    // Acumular hasta tener suficiente duraci√≥n
    const elapsed = Date.now() - lastSendTime;
    if (elapsed >= MIN_AUDIO_DURATION && audioChunks.length > 0) {
      // Enviar chunk acumulado
      sendAudioChunk();
      audioChunks = [];
      lastSendTime = Date.now();
    }
  }
};
```

#### **Paso 1.2: Mejorar Configuraci√≥n de Deepgram**
**Problema**: Par√°metros pueden no ser √≥ptimos
**Soluci√≥n**: Ajustar seg√∫n documentaci√≥n oficial

**Implementaci√≥n:**
```javascript
// En server-websocket.js, transcribeAudio()
const queryParams = new URLSearchParams({
  model: 'nova-2',           // Modelo m√°s preciso
  language: 'es',            // Idioma espa√±ol
  punctuate: 'true',          // Puntuaci√≥n
  smart_format: 'true',      // Formato inteligente
  diarize: 'false',          // No diarizaci√≥n (una sola voz)
  multichannel: 'false',     // Mono channel
  interim_results: 'false'   // Solo resultados finales
});
```

#### **Paso 1.3: Validar Calidad de Audio**
**Problema**: Audio puede estar silencioso
**Soluci√≥n**: Validar nivel de audio antes de enviar

**Implementaci√≥n:**
```javascript
// En cliente, antes de enviar
function validateAudioLevel(audioBlob) {
  return new Promise((resolve) => {
    const audioContext = new AudioContext();
    const reader = new FileReader();
    
    reader.onloadend = async () => {
      const arrayBuffer = reader.result;
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      const channelData = audioBuffer.getChannelData(0);
      
      // Calcular RMS (Root Mean Square) para detectar silencio
      let sum = 0;
      for (let i = 0; i < channelData.length; i++) {
        sum += channelData[i] * channelData[i];
      }
      const rms = Math.sqrt(sum / channelData.length);
      
      // Si RMS es muy bajo, es silencio
      resolve(rms > 0.01); // Threshold ajustable
    };
    
    reader.readAsArrayBuffer(audioBlob);
  });
}
```

#### **Paso 1.4: Debug de Audio**
**Problema**: No sabemos si el audio es v√°lido
**Soluci√≥n**: Guardar audio para verificaci√≥n

**Implementaci√≥n:**
```javascript
// En server-websocket.js (solo para debug)
const fs = require('fs');
fs.writeFileSync(`debug-audio-${Date.now()}.webm`, audioBuffer);
console.log('üíæ Audio guardado para debug');
```

### FASE 2: OPTIMIZACI√ìN DEL FLUJO

#### **Paso 2.1: Streaming Continuo**
**Mejora**: Enviar audio de forma continua sin esperar chunks completos

**Implementaci√≥n:**
- Acumular chunks en buffer
- Enviar cada 1.5-2 segundos
- Procesar en paralelo mientras se captura m√°s audio

#### **Paso 2.2: Manejo de Errores Mejorado**
**Mejora**: Reintentos autom√°ticos y fallbacks

**Implementaci√≥n:**
```javascript
async function transcribeAudioWithRetry(audioBase64, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      return await transcribeAudio(audioBase64);
    } catch (error) {
      if (i === retries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
}
```

### FASE 3: TESTING Y VALIDACI√ìN

#### **Tests a Realizar:**
1. ‚úÖ Audio se captura correctamente
2. ‚úÖ Audio se acumula hasta tener duraci√≥n m√≠nima
3. ‚ö†Ô∏è Audio se env√≠a a Deepgram con formato correcto
4. ‚ö†Ô∏è Deepgram transcribe correctamente
5. ‚úÖ Respuesta de IA se genera
6. ‚úÖ Audio TTS se genera
7. ‚úÖ Audio se reproduce en cliente
8. ‚ö†Ô∏è Flujo completo funciona sin errores

---

## 5. ORDEN DE IMPLEMENTACI√ìN

### **PRIORIDAD ALTA (Resolver primero)**

1. **Acumular chunks de audio** (Paso 1.1)
   - Cambiar de 100ms a acumular 1.5-2 segundos
   - Implementar buffer de acumulaci√≥n
   - **Archivo**: `index.html` l√≠neas ~2104-2163

2. **Ajustar configuraci√≥n Deepgram** (Paso 1.2)
   - Revisar par√°metros seg√∫n documentaci√≥n
   - Agregar par√°metros faltantes si es necesario
   - **Archivo**: `server-websocket.js` l√≠neas ~189-194

3. **Validar calidad de audio** (Paso 1.3)
   - Implementar detecci√≥n de silencio
   - No enviar audio silencioso
   - **Archivo**: `index.html` antes de enviar audio

### **PRIORIDAD MEDIA (Mejoras)**

4. **Debug de audio** (Paso 1.4)
   - Guardar archivos de audio para verificaci√≥n
   - Solo en desarrollo, comentar en producci√≥n

5. **Streaming continuo** (Paso 2.1)
   - Optimizar flujo para menor latencia

6. **Reintentos autom√°ticos** (Paso 2.2)
   - Manejar errores temporales de red

---

## 6. ARCHIVOS A MODIFICAR

### 6.1 `index.html`
**Cambios necesarios:**
- L√≠neas ~2104-2163: Modificar captura de audio para acumular chunks
- Agregar funci√≥n `validateAudioLevel()` antes de enviar
- Modificar `mediaRecorder.start()` para usar tiempos m√°s largos

### 6.2 `server-websocket.js`
**Cambios necesarios:**
- L√≠neas ~189-194: Ajustar query params de Deepgram
- L√≠neas ~158-269: Mejorar validaci√≥n de audio recibido
- Agregar funci√≥n de debug (guardar audio) - opcional

### 6.3 `.env`
**Verificar:**
- `DEEPGRAM_API_KEY` est√° configurada y es v√°lida
- Formato correcto (sin espacios, sin comillas)

---

## 7. CHECKLIST DE IMPLEMENTACI√ìN

### **Pre-Implementaci√≥n:**
- [ ] Revisar documentaci√≥n oficial de Deepgram API
- [ ] Verificar que API key de Deepgram es v√°lida
- [ ] Probar endpoint de Deepgram con curl/Postman

### **Implementaci√≥n:**
- [ ] Modificar acumulaci√≥n de chunks en cliente
- [ ] Ajustar configuraci√≥n de Deepgram
- [ ] Implementar validaci√≥n de nivel de audio
- [ ] Agregar logs detallados
- [ ] Implementar debug de audio (opcional)

### **Testing:**
- [ ] Probar con audio claro y fuerte
- [ ] Probar con audio bajo
- [ ] Probar con silencio
- [ ] Verificar transcripci√≥n correcta
- [ ] Verificar flujo completo STT ‚Üí IA ‚Üí TTS

### **Post-Implementaci√≥n:**
- [ ] Remover c√≥digo de debug
- [ ] Optimizar para producci√≥n
- [ ] Documentar cambios

---

## 8. REFERENCIAS Y DOCUMENTACI√ìN

### **Deepgram API:**
- Documentaci√≥n: https://developers.deepgram.com/
- Endpoint: `POST /v1/listen`
- Modelos: `nova-2`, `general`, `enhanced`
- Formatos soportados: `webm`, `wav`, `mp3`, `ogg`

### **MediaRecorder API:**
- Documentaci√≥n: https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder
- Formatos: `audio/webm`, `audio/webm;codecs=opus`
- Chunks: Configurables con `start(timeslice)`

### **Cartesia API:**
- Documentaci√≥n: https://docs.cartesia.ai/
- Endpoint: `POST /tts/bytes`
- Formatos: `mp3`, `wav`, `webm`
- Sample rates: 16000, 24000, 44100, 48000

---

## 9. CONCLUSI√ìN

### **Problema Principal Identificado:**
Los chunks de audio de 100ms son demasiado cortos para que Deepgram pueda transcribir correctamente. Deepgram necesita m√≠nimo 500ms-1s de audio para procesar.

### **Soluci√≥n Principal:**
Acumular chunks de audio hasta tener m√≠nimo 1.5-2 segundos antes de enviar a Deepgram.

### **Mejoras Adicionales:**
1. Ajustar par√°metros de Deepgram seg√∫n documentaci√≥n
2. Validar nivel de audio antes de enviar
3. Implementar debug para verificar calidad de audio

### **Pr√≥ximos Pasos:**
1. Implementar acumulaci√≥n de chunks (PRIORIDAD 1)
2. Ajustar configuraci√≥n Deepgram (PRIORIDAD 2)
3. Agregar validaci√≥n de audio (PRIORIDAD 3)
4. Testing completo del flujo

---

**Fecha de An√°lisis**: 2025-12-07
**Analista**: Codex (AI Assistant)
**Estado**: Listo para implementaci√≥n

