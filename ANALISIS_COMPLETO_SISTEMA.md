# üîç AN√ÅLISIS COMPLETO DEL SISTEMA - Pipeline Conversacional

**Fecha:** 2026-01-03  
**Estado:** Sistema inestable con m√∫ltiples problemas cr√≠ticos  
**Objetivo:** Limpiar y reconstruir pipeline robusto y estable

---

## üìä PROBLEMAS IDENTIFICADOS

### 1. **AUDIO PRE-GRABADO DEL SALUDO** ‚ùå
**Problema:** El sistema intenta usar audio pre-grabado (`welcome.mp3`) que causa cambio de voz/timbre/tono.

**Ubicaci√≥n:**
- `MEMORIA_PERSISTENTE_PROYECTO.md` menciona `assets/audio/welcome.mp3`
- `socket-server.js:handleInitialGreeting()` genera saludo con TTS (correcto)
- Pero hay referencia a archivo grabado en documentaci√≥n

**Impacto:** 
- Cambio perceptible de voz entre saludo y conversaci√≥n
- El usuario nota claramente la diferencia
- No es "real-time" como deber√≠a ser

**Soluci√≥n:** ‚úÖ ELIMINAR completamente cualquier referencia a audio pre-grabado. Solo TTS en tiempo real.

---

### 2. **M√öLTIPLES MODELOS/VOCES** ‚ùå
**Problema:** El sistema tiene configuraciones contradictorias con m√∫ltiples modelos de voz.

**Estado Actual:**
```javascript
// src/services/voice-services.js:472
model = 'aura-2-diana-es'  // Default en generateVoice()

// src/services/voice-services.js:467
model: 'aura-2-agustina-es'  // Default en legacy call signature

// src/services/voice-services.js:587
async createTTSStreamingConnection(model = 'aura-2-agustina-es')

// src/services/voice-services.js:738
async _generateDeepgramTTS(text, model = 'aura-2-agustina-es')

// src/websocket/socket-server.js:1314
model: 'aura-2-agustina-es'  // En handleInitialGreeting
```

**Logs muestran:**
- Se intenta usar `aura-2-diana-es`
- Deepgram devuelve `aura-asteria-en` (modelo incorrecto)
- Error 1008 (Policy Violation)
- Fallback constante a REST API

**Impacto:**
- Cambios de voz/acento durante la conversaci√≥n
- Errores constantes de WebSocket
- Latencia horrible por fallbacks

**Soluci√≥n:** ‚úÖ UN SOLO MODELO fijo en TODO el sistema. Esperar JSON del usuario.

---

### 3. **WEBSOCKET TTS vs REST API - INESTABILIDAD** ‚ùå
**Problema:** El sistema intenta usar WebSocket TTS pero falla constantemente, cayendo a REST API.

**Estado Actual:**
```javascript
// src/services/voice-services.js:504-528
// üö´ WEBSOCKET DESHABILITADO: Siempre falla con error 1008
if (streaming && text && text.trim() !== '') {
  try {
    const ttsWs = await this.createTTSStreamingConnection(model);
    // ... falla con error 1008
    // Fallback to REST API
  }
}
```

**Logs muestran:**
```
[TTS] ‚ö†Ô∏è Model mismatch! Requested: aura-2-diana-es, Got: aura-asteria-en
[TTS] ‚ùå WebSocket closed with Policy Violation (1008): DATA-0000
[TTS] ‚ö†Ô∏è WebSocket streaming failed, falling back to REST API
[TTS] üéôÔ∏è Generating audio with Deepgram TTS REST API
```

**Impacto:**
- Latencia horrible (timeouts de 10 segundos antes de fallback)
- Cambios constantes entre WebSocket y REST
- El usuario nota "cortes" e "interrupciones"
- No es "real-time" como OpenAI Realtime API

**Soluci√≥n:** ‚úÖ DECIDIR: Usar SOLO REST API (m√°s simple, estable) O arreglar WebSocket completamente. NO cambiar entre ambos.

---

### 4. **M√öLTIPLES TRANSCRIPCIONES PROCES√ÅNDOSE** ‚ùå
**Problema:** El sistema procesa m√∫ltiples transcripciones simult√°neamente, causando m√∫ltiples respuestas.

**Logs muestran:**
```
[DEEPGRAM] ‚úÖ Utterance finalized (idle_timeout): "Hola, est√°s en tiempo"
[DEEPGRAM] ‚úÖ Utterance finalized (Results): "Hola, est√°s en tiempo"
ü§ñ Processing transcript with AI: "Hola, est√°s en tiempo"
[DEEPGRAM] ‚úÖ Utterance finalized (speech_final): "Hola, est√°s en tiempo."
[DEEPGRAM] New transcript while processing - allowing (user spoke again)
ü§ñ Processing transcript with AI: "Hola, est√°s en tiempo."
```

**Impacto:**
- M√∫ltiples respuestas de AI para la misma frase
- Latencia adicional
- Confusi√≥n en el usuario

**Soluci√≥n:** ‚úÖ Mejorar l√≥gica de deduplicaci√≥n en `socket-server.js`.

---

### 5. **CARTESIA TTS HABILITADO PERO NO USADO** ‚ö†Ô∏è
**Problema:** El c√≥digo tiene l√≥gica para Cartesia pero no se usa consistentemente.

**Estado:**
- Cartesia est√° habilitado en `voice-services.js`
- Fallback logic presente
- Pero no se usa porque Deepgram tiene cr√©dito

**Soluci√≥n:** ‚úÖ Eliminar Cartesia completamente si solo usamos Deepgram.

---

## üèóÔ∏è ARQUITECTURA ACTUAL

### Componentes Principales:

1. **Frontend (`index.html`)**
   - Widget Sandra
   - WebSocket client
   - Audio capture (MediaRecorder)
   - Audio playback

2. **Backend (`src/websocket/socket-server.js`)**
   - WebSocket server
   - Manejo de conexiones
   - `handleInitialGreeting()` - Genera saludo con TTS
   - `handleMessage()` - Procesa mensajes del cliente

3. **Voice Services (`src/services/voice-services.js`)**
   - Deepgram STT (Streaming) ‚úÖ Funciona
   - Deepgram TTS (REST API) ‚úÖ Funciona
   - Deepgram TTS (WebSocket) ‚ùå Falla constantemente
   - Cartesia TTS (REST API) ‚ö†Ô∏è Habilitado pero no usado

4. **AI Services (`src/services/voice-services.js:processMessage`)**
   - OpenAI GPT-4o-mini ‚úÖ Fijado como √∫nico modelo
   - Fallbacks eliminados ‚úÖ

---

## üìã PLAN DE LIMPIEZA Y RECONSTRUCCI√ìN

### FASE 1: AN√ÅLISIS Y DOCUMENTACI√ìN ‚úÖ (EN PROGRESO)
- [x] Identificar todos los problemas
- [x] Documentar estado actual
- [ ] Esperar JSON del usuario para configuraci√≥n de modelo √∫nico
- [ ] Crear plan detallado de cambios

### FASE 2: LIMPIEZA DE C√ìDIGO
- [ ] Eliminar referencias a audio pre-grabado (`welcome.mp3`)
- [ ] Eliminar Cartesia TTS completamente
- [ ] Eliminar WebSocket TTS (o arreglarlo completamente, no dejar fallback)
- [ ] Unificar modelo de voz (esperar JSON del usuario)
- [ ] Eliminar c√≥digo muerto y comentarios obsoletos
- [ ] Limpiar l√≥gica de deduplicaci√≥n de transcripciones

### FASE 3: RECONSTRUCCI√ìN
- [ ] Implementar pipeline limpio con un solo modelo
- [ ] Decidir: SOLO REST API TTS (m√°s simple) o arreglar WebSocket
- [ ] Implementar saludo con TTS (no pre-grabado)
- [ ] Optimizar latencia
- [ ] Testing completo

### FASE 4: VALIDACI√ìN
- [ ] Test de llamada completa
- [ ] Verificar latencia
- [ ] Verificar consistencia de voz
- [ ] Verificar estabilidad

---

## üéØ CONFIGURACI√ìN OBJETIVO (PENDIENTE JSON DEL USUARIO)

### Modelo de Voz:
- **√öNICO MODELO:** (Esperando JSON del usuario)
- **Aplicar en:** TODO el sistema (saludo + respuestas)

### Pipeline TTS:
- **Opci√≥n A:** SOLO REST API (m√°s simple, estable, latencia aceptable)
- **Opci√≥n B:** WebSocket TTS arreglado completamente (menor latencia, m√°s complejo)

### AI Model:
- ‚úÖ OpenAI GPT-4o-mini (ya fijado)
- Sin fallbacks

---

## üìù DECISIONES PENDIENTES

1. **Modelo de voz √∫nico:** Esperando JSON del usuario
2. **TTS Pipeline:** REST API solo vs WebSocket arreglado
3. **Eliminaci√≥n de Cartesia:** Confirmar si se usa o no

---

## üîß PR√ìXIMOS PASOS

1. ‚úÖ Completar an√°lisis (ESTE DOCUMENTO)
2. ‚è≥ Esperar JSON del usuario con configuraci√≥n de modelo √∫nico
3. ‚è≥ Crear plan detallado de implementaci√≥n
4. ‚è≥ Ejecutar limpieza
5. ‚è≥ Ejecutar reconstrucci√≥n
6. ‚è≥ Testing y validaci√≥n

---

**Nota:** Este an√°lisis se actualizar√° cuando el usuario proporcione el JSON de configuraci√≥n del modelo √∫nico.
