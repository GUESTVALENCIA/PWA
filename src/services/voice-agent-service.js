/**
 * Deepgram Voice Agent API Service
 * Integrated STT + LLM (OpenAI GPT-4o-mini) + TTS pipeline for minimal latency
 * 
 * Voice Agent API handles the entire pipeline:
 * - Listen (STT) â†’ Think (LLM) â†’ Speak (TTS)
 * - All in one WebSocket connection
 * - Native barge-in support
 * - Optimized for enterprise call quality
 */

import { createClient, AgentEvents } from '@deepgram/sdk';
import logger from '../utils/logger.js';

class VoiceAgentService {
  constructor() {
    this.deepgramApiKey = process.env.DEEPGRAM_API_KEY;
    this.openaiApiKey = process.env.OPENAI_API_KEY;

    if (!this.deepgramApiKey) {
      logger.warn('[VOICE-AGENT] âš ï¸ Deepgram API Key not configured');
      this.deepgram = null;
      return;
    }

    if (!this.openaiApiKey) {
      logger.warn('[VOICE-AGENT] âš ï¸ OpenAI API Key not configured (required for Voice Agent)');
      this.deepgram = null;
      return;
    }

    try {
      this.deepgram = createClient(this.deepgramApiKey);
      logger.info('[VOICE-AGENT] âœ… Deepgram SDK initialized for Voice Agent API');
      logger.info('[VOICE-AGENT] âœ… OpenAI API Key configured (for GPT-4o-mini)');
    } catch (error) {
      logger.error('[VOICE-AGENT] âŒ Failed to initialize Deepgram SDK:', error);
      this.deepgram = null;
    }
  }

  /**
   * Create Voice Agent connection
   * @param {Object} options - Configuration options with event handlers
   * @returns {Object} Voice Agent connection object
   */
  createAgentConnection(options = {}) {
    if (!this.deepgram) {
      throw new Error('Deepgram SDK not initialized - check DEEPGRAM_API_KEY');
    }

    if (!this.openaiApiKey) {
      throw new Error('OpenAI API Key not configured - required for Voice Agent');
    }

    const {
      onUserStartedSpeaking = null,
      onAgentThinking = null,
      onAgentStartedSpeaking = null,
      onConversationText = null,
      onAudio = null,
      onError = null,
      onClose = null
    } = options;

    logger.info('[VOICE-AGENT] ðŸ”Œ Creating Voice Agent connection...');

    // Create Voice Agent connection using Deepgram SDK
    const agent = this.deepgram.agent();

    // Configure agent when Welcome event is received
    // Configure agent when Welcome event is received
    agent.on(AgentEvents.Welcome, () => {
      logger.info('[VOICE-AGENT] âœ… Connected to Voice Agent API');

      // Send Settings message to configure the agent
      // GPT-4o-mini as preferred model (user requirement)
      agent.send({
        type: 'Settings',
        agent: {
          listen: {
            provider: {
              type: 'deepgram',
              model: 'nova-2-phonecall' // Optimized for phone calls
            }
          },
          think: {
            provider: {
              type: 'open_ai',
              model: 'gpt-4o-mini' // Preferred: GPT-4o-mini (user requirement)
            },
            prompt: `Eres Sandra, la asistente virtual de Guests Valencia, especializada en hospitalidad y turismo.
Responde SIEMPRE en espaÃ±ol neutro (EspaÃ±a), con buena ortografÃ­a y gramÃ¡tica.
Nunca cambies tu personalidad ni uses jergas de otros paÃ­ses.
ActÃºa como una experta en Hospitalidad y Turismo.
SÃ© breve: mÃ¡ximo 2-3 frases salvo que se pida detalle.
SÃ© amable, profesional y Ãºtil.`
          },
          speak: {
            provider: {
              type: 'deepgram',
              model: 'aura-2-agustina-es' // Spanish Peninsular female voice (Agustina)
            }
          },
          language: 'es',
          greeting: 'Hola, soy Sandra de Guests Valencia. Â¿En quÃ© puedo ayudarte?'
        }
      });

      logger.info('[VOICE-AGENT] âœ… Settings sent (GPT-4o-mini, voz Agustina, modelo nova-2-phonecall)');
    });

    // Handle user started speaking (for barge-in detection)
    if (onUserStartedSpeaking) {
      agent.on(AgentEvents.UserStartedSpeaking, (data) => {
        logger.debug('[VOICE-AGENT] ðŸ‘¤ User started speaking');
        onUserStartedSpeaking(data);
      });
    }

    // Handle agent thinking (LLM processing)
    if (onAgentThinking) {
      agent.on(AgentEvents.AgentThinking, (data) => {
        logger.debug('[VOICE-AGENT] ðŸ¤” Agent thinking (LLM processing)');
        onAgentThinking(data);
      });
    }

    // Handle agent started speaking (TTS started)
    if (onAgentStartedSpeaking) {
      agent.on(AgentEvents.AgentStartedSpeaking, (data) => {
        logger.info('[VOICE-AGENT] ðŸ—£ï¸ Agent started speaking (TTS audio started)');
        this.isAgentSpeaking = true; // Track state
        onAgentStartedSpeaking(data);
      });
    }

    // Handle agent completed speaking (New event handler)
    agent.on(AgentEvents.AgentCompletedSpeaking, (data) => {
      logger.debug('[VOICE-AGENT] ðŸ¤ Agent finished speaking');
      this.isAgentSpeaking = false;
    });

    // Handle conversation text (transcriptions and responses)
    if (onConversationText) {
      let lastAgentResponse = ''; // Simple dedupe memory

      agent.on(AgentEvents.ConversationText, (data) => {
        const text = data?.content || data?.text || ''; // Check 'content' field too
        const role = data?.role;

        if (text) {
          // Deduplication Logic for Agent Responses
          if (role === 'assistant') {
            if (text === lastAgentResponse) {
              logger.warn(`[VOICE-AGENT] ðŸ›‘ Duplicate response blocked: "${text.substring(0, 30)}..."`);
              return; // Skip duplicate
            }
            lastAgentResponse = text;
          }

          logger.debug(`[VOICE-AGENT] ðŸ’¬ Conversation text (${role}): "${text.substring(0, 50)}${text.length > 50 ? '...' : ''}"`);
          onConversationText(data);
        }
      });
    }

    // Handle audio (TTS output - PCM audio chunks)
    if (onAudio) {
      agent.on(AgentEvents.Audio, (audio) => {
        logger.debug('[VOICE-AGENT] ðŸ”Š Audio chunk received (PCM)');
        onAudio(audio);
      });
    }

    // Handle errors
    agent.on(AgentEvents.Error, (error) => {
      logger.error('[VOICE-AGENT] âŒ Error:', error);
      if (onError) {
        onError(error);
      }
    });

    // Handle close
    if (onClose) {
      agent.on(AgentEvents.Close, () => {
        logger.info('[VOICE-AGENT] ðŸ”Œ Connection closed');
        onClose();
      });
    }

    return agent;
  }

  /**
   * Check if Voice Agent API is available and configured
   * @returns {boolean} True if both Deepgram and OpenAI API keys are configured
   */
  isConfigured() {
    return !!(this.deepgram && this.openaiApiKey);
  }
}

export default VoiceAgentService;
