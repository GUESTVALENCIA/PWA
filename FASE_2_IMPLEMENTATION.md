# FASE 2 - IMPLEMENTACI√ìN COMPLETA
## Chat por Texto: OpenAI + Deepgram + Sandra Voice

**Status:** ‚úÖ IMPLEMENTACI√ìN LISTA PARA ACTIVAR
**Fecha:** Diciembre 27, 2025

---

## üìã RESUMEN

**Arquitectura FASE 2:**
```
Usuario habla
    ‚Üì
MediaRecorder captura audio (webm)
    ‚Üì
Env√≠a a /api/sandra/chat-text
    ‚Üì
Deepgram transcribe audio ‚Üí texto
    ‚Üì
gpt-4o-mini procesa texto
    ‚Üì
Respuesta texto a playFallback()
    ‚Üì
Voz de Sandra reproduce respuesta
```

**Ventajas:**
- ‚úÖ NO hay Realtime API (sin audio generation obligatoria)
- ‚úÖ Solo voz de Sandra (sin t√≠o de OpenAI)
- ‚úÖ M√°s barato: ~$0.30 por llamada vs $2-5 actual
- ‚úÖ Conversaci√≥n natural por texto
- ‚úÖ Soporte para historial conversacional

---

## üìÅ ARCHIVOS CREADOS

### 1. **Backend API: `/api/sandra/chat-text.js`**
- Procesa audio con Deepgram STT
- Env√≠a texto a gpt-4o-mini
- Retorna respuesta
- **Requiere:** OPENAI_API_KEY + DEEPGRAM_API_KEY

### 2. **Frontend JS: `/assets/js/speech-to-text-chat.js`**
- Captura audio con MediaRecorder
- Env√≠a a chat-text.js
- Reproduces con voz de Sandra
- **M√©todos p√∫blicos:**
  - `window.speechToChatSystem.startListening()`
  - `window.speechToChatSystem.stopListening()`
  - `window.speechToChatSystem.setLanguage('es'|'en'|'fr')`
  - `window.speechToChatSystem.clearHistory()`

---

## ‚öôÔ∏è CONFIGURACI√ìN REQUERIDA

### Variables de Entorno (.env)

Aseg√∫rate que tengas en tu `.env`:

```bash
# OpenAI
OPENAI_API_KEY=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

# Deepgram
DEEPGRAM_API_KEY=53202ecf825c59e8ea498f7cf68c4822c2466005
```

---

## üîå INTEGRACI√ìN EN index.html

Agregar en la secci√≥n `<head>`:

```html
<!-- FASE 2: Speech-to-Text Chat System -->
<script src="/assets/js/speech-to-text-chat.js" defer></script>
```

---

## üéôÔ∏è IMPLEMENTACI√ìN EN HTML

### Opci√≥n A: Botones Simples

```html
<!-- Botones para start/stop listening -->
<button onclick="window.speechToChatSystem.startListening()">
  üé§ Hablar
</button>

<button onclick="window.speechToChatSystem.stopListening()">
  ‚èπÔ∏è Detener
</button>

<!-- Indicador de estado -->
<div id="status">Listo para escuchar</div>

<script>
  // Monitorear estado
  setInterval(() => {
    const status = window.speechToChatSystem.getStatus();
    document.getElementById('status').textContent =
      status.isListening ? 'üî¥ Escuchando...' : '‚úÖ Listo';
  }, 100);
</script>
```

### Opci√≥n B: Con Selector de Idioma

```html
<div class="voice-controls">
  <!-- Selector de idioma -->
  <select onchange="window.speechToChatSystem.setLanguage(this.value)">
    <option value="es">Espa√±ol</option>
    <option value="en">English</option>
    <option value="fr">Fran√ßais</option>
  </select>

  <!-- Control de voz -->
  <button id="voiceBtn" onclick="toggleVoiceInput()">
    üé§ Escuchar
  </button>
</div>

<script>
  let isListening = false;

  function toggleVoiceInput() {
    if (!isListening) {
      window.speechToChatSystem.startListening();
      document.getElementById('voiceBtn').textContent = '‚èπÔ∏è Detener';
      isListening = true;
    } else {
      window.speechToChatSystem.stopListening();
      document.getElementById('voiceBtn').textContent = 'üé§ Escuchar';
      isListening = false;
    }
  }
</script>
```

---

## üìù FLUJO DE CONVERSACI√ìN

### Ejemplo: Usuario dice "Hola"

```
1. Usuario hace click en "Hablar"
   ‚Üí startListening() inicia MediaRecorder

2. Usuario dice: "Hola, buenos d√≠as"
   ‚Üí Audio capturado en WAV

3. Usuario hace click en "Detener"
   ‚Üí stopListening() env√≠a audio a /api/sandra/chat-text

4. Backend:
   ‚Üí Deepgram transcribe: "Hola, buenos d√≠as"
   ‚Üí gpt-4o-mini responde: "Buenos d√≠as, bienvenido a GuestsValencia..."

5. Frontend recibe respuesta
   ‚Üí playResponse() toca voz de Sandra
   ‚Üí Usuario escucha SOLO voz de Sandra

6. Sistema listo para siguiente pregunta
   ‚Üí Historial mantiene contexto conversacional
```

---

## üîç DEBUGGING

### Consola del Navegador (F12)

```javascript
// Ver estado del sistema
window.speechToChatSystem.getStatus()

// Ver historial conversacional
window.speechToChatSystem.getHistory()

// Limpiar historial
window.speechToChatSystem.clearHistory()

// Logs autom√°ticos
[SPEECH-CHAT] ‚ÑπÔ∏è  Sistema inicializado
[SPEECH-CHAT] ‚úÖ Audio capturado
[CHAT-TEXT] Usuario: "tu texto aqu√≠"
```

### Backend Logs

```bash
[CHAT-TEXT] Usuario texto: "tu texto aqu√≠"
[CHAT-TEXT] Procesando audio con Deepgram...
[CHAT-TEXT] Deepgram transcripci√≥n: "tu texto aqu√≠"
[CHAT-TEXT] Enviando a gpt-4o-mini...
[CHAT-TEXT] Respuesta Sandra: "respuesta aqu√≠"
```

---

## üí∞ COSTOS FASE 2

### Por Llamada de 1 Minuto:

| Servicio | Costo |
|----------|-------|
| Deepgram STT | $0.0043 |
| gpt-4o-mini | $0.15-0.30 |
| Total | **~$0.30** |

### Comparativa:
- **ANTES (Realtime):** $2-5 por llamada
- **DESPU√âS (FASE 2):** $0.30 por llamada
- **AHORRO:** 85-94%

---

## ‚úÖ LISTA DE VERIFICACI√ìN IMPLEMENTACI√ìN

- [x] Archivo chat-text.js creado
- [x] Archivo speech-to-text-chat.js creado
- [x] Soporte para Deepgram integrado
- [x] Soporte para gpt-4o-mini integrado
- [x] Sistema de historial conversacional
- [x] Detecci√≥n de tipo de respuesta
- [x] Integraci√≥n con playFallback()
- [ ] Script agregado a index.html
- [ ] Botones implementados en UI
- [ ] Variables de entorno configuradas
- [ ] Pruebas funcionales completadas

---

## üöÄ PR√ìXIMOS PASOS

### 1. Agregar script a index.html
```html
<script src="/assets/js/speech-to-text-chat.js" defer></script>
```

### 2. Crear botones en la interfaz
Use Opci√≥n A o B arriba

### 3. Probar en navegador:
- F12 ‚Üí Console
- Verificar logs [SPEECH-CHAT]
- Hacer prueba de conversaci√≥n

### 4. Monitorear costos:
- OpenAI usage dashboard
- Deepgram usage dashboard

---

## üîß TROUBLESHOOTING

**Error: "Deepgram API key not configured"**
‚Üí Agregar DEEPGRAM_API_KEY a .env

**Error: "OpenAI API key not configured"**
‚Üí Agregar OPENAI_API_KEY a .env

**No se escucha audio del navegador**
‚Üí Verificar permisos de micr√≥fono
‚Üí Check navegador soporta MediaRecorder

**Respuesta lenta**
‚Üí Normal: Deepgram (~1s) + OpenAI (~2s) = ~3s total
‚Üí M√°s r√°pido que Realtime en muchos casos

**Accento mal interpretado**
‚Üí Deepgram soporta muchos acentos
‚Üí Si falla, Espa√±ol USA est√° optimizado (es-US)

---

## üìû SOPORTE

**Documentaci√≥n:**
- OpenAI API: https://platform.openai.com/docs
- Deepgram: https://developers.deepgram.com
- gpt-4o-mini: Modelo de texto puro, no de audio

**Logs para debuggear:**
- Backend: `/api/sandra/chat-text.js` (l√≠neas 49-78)
- Frontend: `/assets/js/speech-to-text-chat.js` (l√≠neas 22-26)

---

**¬øListo para activar FASE 2?**

Solo falta:
1. Agregar script a index.html
2. Crear botones en UI
3. Probar en navegador

¬°Vamos!
