# FASE 2 - IMPLEMENTACIÃ“N COMPLETA
## Chat por Texto: OpenAI + Deepgram + Sandra Voice

**Status:** âœ… IMPLEMENTACIÃ“N LISTA PARA ACTIVAR
**Fecha:** Diciembre 27, 2025

---

## ğŸ“‹ RESUMEN

**Arquitectura FASE 2:**
```
Usuario habla
    â†“
MediaRecorder captura audio (webm)
    â†“
EnvÃ­a a /api/sandra/chat-text
    â†“
Deepgram transcribe audio â†’ texto
    â†“
gpt-4o-mini procesa texto
    â†“
Respuesta texto a playFallback()
    â†“
Voz de Sandra reproduce respuesta
```

**Ventajas:**
- âœ… NO hay Realtime API (sin audio generation obligatoria)
- âœ… Solo voz de Sandra (sin tÃ­o de OpenAI)
- âœ… MÃ¡s barato: ~$0.30 por llamada vs $2-5 actual
- âœ… ConversaciÃ³n natural por texto
- âœ… Soporte para historial conversacional

---

## ğŸ“ ARCHIVOS CREADOS

### 1. **Backend API: `/api/sandra/chat-text.js`**
- Procesa audio con Deepgram STT
- EnvÃ­a texto a gpt-4o-mini
- Retorna respuesta
- **Requiere:** OPENAI_API_KEY + DEEPGRAM_API_KEY

### 2. **Frontend JS: `/assets/js/speech-to-text-chat.js`**
- Captura audio con MediaRecorder
- EnvÃ­a a chat-text.js
- Reproduces con voz de Sandra
- **MÃ©todos pÃºblicos:**
  - `window.speechToChatSystem.startListening()`
  - `window.speechToChatSystem.stopListening()`
  - `window.speechToChatSystem.setLanguage('es'|'en'|'fr')`
  - `window.speechToChatSystem.clearHistory()`

---

## âš™ï¸ CONFIGURACIÃ“N REQUERIDA

### Variables de Entorno (.env)

AsegÃºrate que tengas en tu `.env`:

```bash
# OpenAI - Agregar tu API key aquÃ­ (no commitear)
OPENAI_API_KEY=your_openai_api_key_here

# Deepgram - Agregar tu API key aquÃ­ (no commitear)
DEEPGRAM_API_KEY=your_deepgram_api_key_here
```

**IMPORTANTE:** Nunca commits archivos `.env` o archivos con API keys reales.
Las claves deben estar solo en tu mÃ¡quina local o en variables de entorno del servidor.

---

## ğŸ”Œ INTEGRACIÃ“N EN index.html

Agregar en la secciÃ³n `<head>`:

```html
<!-- FASE 2: Speech-to-Text Chat System -->
<script src="/assets/js/speech-to-text-chat.js" defer></script>
```

---

## ğŸ™ï¸ IMPLEMENTACIÃ“N EN HTML

### OpciÃ³n A: Botones Simples

```html
<!-- Botones para start/stop listening -->
<button onclick="window.speechToChatSystem.startListening()">
  ğŸ¤ Hablar
</button>

<button onclick="window.speechToChatSystem.stopListening()">
  â¹ï¸ Detener
</button>

<!-- Indicador de estado -->
<div id="status">Listo para escuchar</div>

<script>
  // Monitorear estado
  setInterval(() => {
    const status = window.speechToChatSystem.getStatus();
    document.getElementById('status').textContent =
      status.isListening ? 'ğŸ”´ Escuchando...' : 'âœ… Listo';
  }, 100);
</script>
```

### OpciÃ³n B: Con Selector de Idioma

```html
<div class="voice-controls">
  <!-- Selector de idioma -->
  <select onchange="window.speechToChatSystem.setLanguage(this.value)">
    <option value="es">EspaÃ±ol</option>
    <option value="en">English</option>
    <option value="fr">FranÃ§ais</option>
  </select>

  <!-- Control de voz -->
  <button id="voiceBtn" onclick="toggleVoiceInput()">
    ğŸ¤ Escuchar
  </button>
</div>

<script>
  let isListening = false;

  function toggleVoiceInput() {
    if (!isListening) {
      window.speechToChatSystem.startListening();
      document.getElementById('voiceBtn').textContent = 'â¹ï¸ Detener';
      isListening = true;
    } else {
      window.speechToChatSystem.stopListening();
      document.getElementById('voiceBtn').textContent = 'ğŸ¤ Escuchar';
      isListening = false;
    }
  }
</script>
```

---

## ğŸ“ FLUJO DE CONVERSACIÃ“N

### Ejemplo: Usuario dice "Hola"

```
1. Usuario hace click en "Hablar"
   â†’ startListening() inicia MediaRecorder

2. Usuario dice: "Hola, buenos dÃ­as"
   â†’ Audio capturado en WAV

3. Usuario hace click en "Detener"
   â†’ stopListening() envÃ­a audio a /api/sandra/chat-text

4. Backend:
   â†’ Deepgram transcribe: "Hola, buenos dÃ­as"
   â†’ gpt-4o-mini responde: "Buenos dÃ­as, bienvenido a GuestsValencia..."

5. Frontend recibe respuesta
   â†’ playResponse() toca voz de Sandra
   â†’ Usuario escucha SOLO voz de Sandra

6. Sistema listo para siguiente pregunta
   â†’ Historial mantiene contexto conversacional
```

---

## ğŸ” DEBUGGING

### Consola del Navegador (F12)

```javascript
// Ver estado del sistema
window.speechToChatSystem.getStatus()

// Ver historial conversacional
window.speechToChatSystem.getHistory()

// Limpiar historial
window.speechToChatSystem.clearHistory()

// Logs automÃ¡ticos
[SPEECH-CHAT] â„¹ï¸  Sistema inicializado
[SPEECH-CHAT] âœ… Audio capturado
[CHAT-TEXT] Usuario: "tu texto aquÃ­"
```

### Backend Logs

```bash
[CHAT-TEXT] Usuario texto: "tu texto aquÃ­"
[CHAT-TEXT] Procesando audio con Deepgram...
[CHAT-TEXT] Deepgram transcripciÃ³n: "tu texto aquÃ­"
[CHAT-TEXT] Enviando a gpt-4o-mini...
[CHAT-TEXT] Respuesta Sandra: "respuesta aquÃ­"
```

---

## ğŸ’° COSTOS FASE 2

### Por Llamada de 1 Minuto:

| Servicio | Costo |
|----------|-------|
| Deepgram STT | $0.0043 |
| gpt-4o-mini | $0.15-0.30 |
| Total | **~$0.30** |

### Comparativa:
- **ANTES (Realtime):** $2-5 por llamada
- **DESPUÃ‰S (FASE 2):** $0.30 por llamada
- **AHORRO:** 85-94%

---

## âœ… LISTA DE VERIFICACIÃ“N IMPLEMENTACIÃ“N

- [x] Archivo chat-text.js creado
- [x] Archivo speech-to-text-chat.js creado
- [x] Soporte para Deepgram integrado
- [x] Soporte para gpt-4o-mini integrado
- [x] Sistema de historial conversacional
- [x] DetecciÃ³n de tipo de respuesta
- [x] IntegraciÃ³n con playFallback()
- [ ] Script agregado a index.html
- [ ] Botones implementados en UI
- [ ] Variables de entorno configuradas
- [ ] Pruebas funcionales completadas

---

## ğŸš€ PRÃ“XIMOS PASOS

### 1. Agregar script a index.html
```html
<script src="/assets/js/speech-to-text-chat.js" defer></script>
```

### 2. Crear botones en la interfaz
Use OpciÃ³n A o B arriba

### 3. Probar en navegador:
- F12 â†’ Console
- Verificar logs [SPEECH-CHAT]
- Hacer prueba de conversaciÃ³n

### 4. Monitorear costos:
- OpenAI usage dashboard
- Deepgram usage dashboard

---

## ğŸ”§ TROUBLESHOOTING

**Error: "Deepgram API key not configured"**
â†’ Agregar DEEPGRAM_API_KEY a .env

**Error: "OpenAI API key not configured"**
â†’ Agregar OPENAI_API_KEY a .env

**No se escucha audio del navegador**
â†’ Verificar permisos de micrÃ³fono
â†’ Check navegador soporta MediaRecorder

**Respuesta lenta**
â†’ Normal: Deepgram (~1s) + OpenAI (~2s) = ~3s total
â†’ MÃ¡s rÃ¡pido que Realtime en muchos casos

**Accento mal interpretado**
â†’ Deepgram soporta muchos acentos
â†’ Si falla, EspaÃ±ol USA estÃ¡ optimizado (es-US)

---

## ğŸ“ SOPORTE

**DocumentaciÃ³n:**
- OpenAI API: https://platform.openai.com/docs
- Deepgram: https://developers.deepgram.com
- gpt-4o-mini: Modelo de texto puro, no de audio

**Logs para debuggear:**
- Backend: `/api/sandra/chat-text.js` (lÃ­neas 49-78)
- Frontend: `/assets/js/speech-to-text-chat.js` (lÃ­neas 22-26)

---

**Â¿Listo para activar FASE 2?**

Solo falta:
1. Agregar script a index.html
2. Crear botones en UI
3. Probar en navegador

Â¡Vamos!
