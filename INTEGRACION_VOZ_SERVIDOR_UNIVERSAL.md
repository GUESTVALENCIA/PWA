# ğŸ¤ INTEGRACIÃ“N DEL SISTEMA DE VOZ AL SERVIDOR UNIVERSAL MCP

## âœ… Cambios Realizados

### 1. **Actualizado `src/websocket/socket-server.js`**

- âœ… Agregado soporte para mensajes con formato `route`/`action` (sistema de voz)
- âœ… Mantenido soporte para formato `type` (orquestaciÃ³n existente)
- âœ… Implementadas funciones:
  - `handleVoiceMessage()` - Router principal para mensajes de voz
  - `handleAudioSTT()` - Procesa audio del usuario (STT â†’ IA â†’ TTS)
  - `handleAudioTTS()` - Genera audio desde texto
  - `handleWelcomeMessage()` - EnvÃ­a saludo inicial grabado

### 2. **Creado `src/services/voice-services.js`**

Servicio completo que integra:
- âœ… **Deepgram** - Speech-to-Text (STT)
- âœ… **Cartesia** - Text-to-Speech (TTS)
- âœ… **Gemini/GPT-4/Groq** - Procesamiento de IA (con fallbacks)
- âœ… **Welcome Audio** - Manejo del archivo de saludo grabado

### 3. **Actualizado `server.js`**

- âœ… InicializaciÃ³n de servicios de voz
- âœ… Paso de servicios de voz al WebSocket handler

## ğŸ“‹ Formato de Mensajes Soportados

### Cliente â†’ Servidor (Audio STT):
```json
{
  "route": "audio",
  "action": "stt",
  "payload": {
    "audio": "base64Audio...",
    "format": "webm",
    "mimeType": "audio/webm;codecs=opus"
  }
}
```

### Cliente â†’ Servidor (Ready):
```json
{
  "route": "conserje",
  "action": "message",
  "payload": {
    "type": "ready",
    "message": "Cliente listo para recibir saludo"
  }
}
```

### Servidor â†’ Cliente (Audio TTS):
```json
{
  "route": "audio",
  "action": "tts",
  "payload": {
    "audio": "base64AudioResponse...",
    "format": "mp3",
    "text": "Respuesta de Sandra",
    "isWelcome": false
  }
}
```

## ğŸ”„ Flujo Completo

1. **Usuario inicia llamada** â†’ Widget conecta WebSocket
2. **Cliente envÃ­a `ready`** â†’ `{route: 'conserje', action: 'message', payload: {type: 'ready'}}`
3. **Servidor envÃ­a saludo** â†’ Audio grabado (welcome.mp3) o TTS
4. **Usuario habla** â†’ Audio capturado y enviado
5. **Servidor procesa**:
   - STT (Deepgram) â†’ Transcribe audio
   - IA (Gemini/GPT-4) â†’ Genera respuesta
   - TTS (Cartesia) â†’ Convierte respuesta a audio
6. **Servidor envÃ­a audio** â†’ Cliente reproduce respuesta

## ğŸ“¦ Variables de Entorno Requeridas

```bash
# STT (Deepgram)
DEEPGRAM_API_KEY=...

# TTS (Cartesia)
CARTESIA_API_KEY=...
CARTESIA_VOICE_ID=sandra

# IA (al menos una)
GEMINI_API_KEY=...
OPENAI_API_KEY=...
GROQ_API_KEY=...
PREFERRED_AI_PROVIDER=gemini  # gemini, openai, o groq
```

## ğŸš€ PrÃ³ximos Pasos

1. **Commit y Push a GitHub**:
   ```bash
   git add .
   git commit -m "feat: Integrar sistema de voz al servidor universal MCP"
   git push origin main
   ```

2. **Render auto-desplegarÃ¡** (si auto-deploy estÃ¡ habilitado)

3. **Verificar variables de entorno en Render**:
   - Dashboard â†’ PWA service â†’ Environment
   - Asegurar que todas las API keys estÃ©n configuradas

4. **Probar la conexiÃ³n**:
   - El widget deberÃ­a conectarse sin errores "Unknown message type"
   - El flujo completo de voz deberÃ­a funcionar

## ğŸ“ Notas

- El servidor ahora soporta **AMBOS** formatos de mensaje:
  - `{type, payload}` â†’ Para orquestaciÃ³n multi-agente
  - `{route, action, payload}` â†’ Para sistema de voz
  
- Si falta `welcome.mp3`, se usa TTS como fallback automÃ¡tico

- Los servicios de voz se inicializan de forma opcional (no bloquean el servidor si fallan)

- El sistema tiene fallbacks automÃ¡ticos para IA:
  1. Gemini (preferido)
  2. OpenAI GPT-4o
  3. Groq Qwen 2.5

## âœ… Estado

**CÃ³digo completado y listo para deployment**

El cliente (widget) ya estÃ¡ preparado y funcionando. Una vez desplegado, el servidor procesarÃ¡ correctamente los mensajes de voz.
