# üéØ RESPUESTAS A CHATGPT 5.2 THINKING + PLAN DE IMPLEMENTACI√ìN

## üìã RESPUESTAS A LAS PREGUNTAS DE CHATGPT

### 1. ¬øTu TTS de Deepgram ahora mismo lo llamas por REST o ya tienes Speak WebSocket?

**RESPUESTA: REST API (NO WebSocket)**

```javascript
// ACTUAL (src/services/voice-services.js l√≠nea 305):
const response = await fetch(`https://api.deepgram.com/v1/speak?model=${model}&encoding=mp3`, {
  method: 'POST',
  headers: {
    'Authorization': `Token ${this.deepgramApiKey}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({ text })
});

// Problemas:
// ‚ùå MP3 encoding (tiempo de codificaci√≥n)
// ‚ùå Base64 encoding (33% overhead)
// ‚ùå Espera respuesta completa
// ‚ùå No streaming
```

**Necesitamos:** Migrar a Deepgram TTS WebSocket streaming con `encoding=linear16` (PCM directo)

---

### 2. ¬øEn cliente est√°s dispuesto a pasar de <audio> a AudioWorklet (s√≠/no)?

**RESPUESTA: S√ç, estamos dispuestos**

**Estado actual:**
- ‚ùå Usamos `<audio>` element con base64 ‚Üí Blob ‚Üí URL
- ‚ùå Esperamos `canplaythrough` (latencia alta)
- ‚ùå Usamos `ScriptProcessorNode` (deprecated) para captura
- ‚ùå Buffer manual, sin control fino

**Necesitamos:** Migrar a AudioWorklet para:
- ‚úÖ Reproducci√≥n PCM directa
- ‚úÖ Cola m√≠nima
- ‚úÖ Start r√°pido
- ‚úÖ Clear inmediato (barge-in real)

---

## üî¥ LOS 2 "ELEFANTES" QUE MATAN LA LATENCIA

### Elefante #1: MP3 + Base64 + <audio>
**Impacto:** -300-800ms de latencia percibida

**Problemas:**
1. MP3 requiere codificaci√≥n en servidor
2. Base64 a√±ade 33% de overhead
3. Decodificaci√≥n en cliente (atob + Blob)
4. `<audio>` bufferiza m√°s de lo necesario
5. `canplaythrough` espera buffer completo

**Soluci√≥n:** Deepgram TTS WebSocket + PCM (linear16) + AudioWorklet

### Elefante #2: Pipeline "por turnos"
**Impacto:** -400-600ms de latencia

**Problema actual:**
```
STT (completo) ‚Üí espera ‚Üí LLM (completo) ‚Üí espera ‚Üí TTS (completo) ‚Üí Audio
```

**Soluci√≥n:** Pipeline paralelo con streaming incremental

---

## üöÄ PLAN DE IMPLEMENTACI√ìN (ORDEN EXACTO DE CHATGPT)

### FASE 1: Deepgram TTS WebSocket + PCM (PRIORIDAD #1)

**Objetivo:** Eliminar MP3 + base64 + <audio>

**Implementaci√≥n:**

#### 1.1. Servidor: Deepgram TTS WebSocket Streaming

```javascript
// Nuevo m√©todo en voice-services.js
async createTTSStreamingConnection(text, options = {}) {
  const ws = new WebSocket('wss://api.deepgram.com/v1/speak', {
    headers: {
      'Authorization': `Token ${this.deepgramApiKey}`,
      'Content-Type': 'application/json'
    }
  });

  ws.on('open', () => {
    // Enviar configuraci√≥n
    ws.send(JSON.stringify({
      type: 'Configure',
      model: 'aura-2-thalia-es',
      encoding: 'linear16', // PCM directo (no MP3)
      sample_rate: 24000
    }));

    // Enviar texto en chunks
    this.sendTextChunks(ws, text);
  });

  return ws; // Retornar WebSocket para streaming
}
```

#### 1.2. Cliente: AudioWorklet para Reproducci√≥n PCM

```javascript
// Nuevo: audio-worklet-processor.js
class PCMPlaybackProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.audioQueue = [];
    this.sampleRate = 24000;
  }

  process(inputs, outputs) {
    const output = outputs[0];
    if (output.length > 0 && this.audioQueue.length > 0) {
      const channel = output[0];
      const audioData = this.audioQueue.shift();
      // Reproducir PCM directamente
      for (let i = 0; i < Math.min(channel.length, audioData.length); i++) {
        channel[i] = audioData[i];
      }
    }
    return true;
  }
}

registerProcessor('pcm-playback-processor', PCMPlaybackProcessor);
```

**Beneficio esperado:** -300-800ms de latencia percibida

---

### FASE 2: Separar Media Plane y Control Plane

**Objetivo:** Reducir bloqueo por colas internas

**Implementaci√≥n:**

```javascript
// Servidor: 3 WebSockets separados
// WS #1: Audio Input (binario, prioridad m√°xima)
// WS #2: Audio Output (binario PCM, prioridad m√°xima)
// WS #3: Control/Eventos (JSON, prioridad normal)
```

**Beneficio esperado:** Mejor regularidad, menos bloqueos

---

### FASE 3: TTS Incremental con Chunking

**Objetivo:** Primer audio mucho antes

**Implementaci√≥n:**

```javascript
// Buffer inteligente de texto del LLM
let textBuffer = '';
let chunkSize = 60-120; // caracteres

// Cuando LLM genera texto:
onLLMChunk(chunk) {
  textBuffer += chunk;
  
  // Detectar fin de frase o l√≠mite de tama√±o
  if (/[.?!]\s*$/.test(textBuffer) || textBuffer.length >= chunkSize) {
    // Enviar chunk a Deepgram TTS
    ttsStream.send({
      type: 'Speak',
      text: textBuffer
    });
    
    // Flush para arrancar audio pronto
    if (firstChunk) {
      ttsStream.send({ type: 'Flush' });
    }
    
    textBuffer = '';
  }
}

// Al final de respuesta LLM:
onLLMComplete() {
  if (textBuffer) {
    ttsStream.send({ type: 'Speak', text: textBuffer });
    ttsStream.send({ type: 'Flush' }); // Flush final
  }
}
```

**Beneficio esperado:** Primer audio 200-400ms antes

---

### FASE 4: Barge-in Real

**Objetivo:** Corte duro cuando usuario habla

**Implementaci√≥n:**

```javascript
// Cuando detectamos VAD/SpeechStarted:
onUserSpeechDetected() {
  // 1. Abort LLM stream
  llmStream.abort();
  
  // 2. Clear Deepgram TTS buffer
  ttsStream.send({ type: 'Clear' });
  
  // 3. Vaciar cola de AudioWorklet
  audioWorkletNode.port.postMessage({ type: 'clear' });
}
```

**Beneficio esperado:** Sensaci√≥n "en llamada" vs "en reproducci√≥n"

---

### FASE 5: Turn Detection Mejorado

**Objetivo:** Empezar antes, sin esperar utterance_end completo

**Implementaci√≥n:**

```javascript
// Usar is_final y speech_final en lugar de solo utterance_end
onTranscriptionResult(message) {
  if (message.is_final && message.speech_final) {
    // Disparar respuesta inmediatamente
    startLLMProcessing(message.transcript);
  } else if (message.is_final && message.transcript.length > 40) {
    // Preparar LLM (empezar a procesar)
    prepareLLM(message.transcript);
  }
}
```

**Beneficio esperado:** -100-200ms en turn detection

---

### FASE 6: Ajustes Finos

1. **Input chunks:** 250ms ‚Üí 100ms (despu√©s de arreglar audio-out)
2. **TCP_NODELAY:** `ws.setNoDelay(true)` en servidor
3. **Sample rate:** Fijar a 24000Hz para evitar resample

---

## üìä IMPACTO ESPERADO TOTAL

| Mejora | Latencia Reducida |
|--------|-------------------|
| TTS WebSocket + PCM + AudioWorklet | -300-800ms |
| Pipeline paralelo + chunking | -400-600ms |
| Barge-in real | -200-300ms |
| Turn detection mejorado | -100-200ms |
| Separar media/control plane | -50-100ms |
| Ajustes finos | -50-100ms |
| **TOTAL** | **-1100-2100ms** |

**Latencia objetivo:** ~650-1650ms (cercano a WebRTC ~700-1400ms)

---

## ‚úÖ CHECKLIST DE IMPLEMENTACI√ìN

### Fase 1: TTS WebSocket + PCM (CR√çTICO)
- [ ] Implementar `createTTSStreamingConnection()` en servidor
- [ ] Cambiar encoding a `linear16` (PCM)
- [ ] Crear AudioWorklet processor para PCM
- [ ] Migrar cliente de `<audio>` a AudioWorklet
- [ ] Eliminar base64 encoding

### Fase 2: Separar WebSockets
- [ ] Crear WS #1: Audio Input (binario)
- [ ] Crear WS #2: Audio Output (binario PCM)
- [ ] Mantener WS #3: Control (JSON)

### Fase 3: TTS Incremental
- [ ] Buffer inteligente de texto LLM
- [ ] Chunking (60-120 chars / fin de frase)
- [ ] Implementar Speak + Flush moderado

### Fase 4: Barge-in Real
- [ ] Detectar VAD/SpeechStarted
- [ ] Abort LLM stream
- [ ] Clear Deepgram TTS
- [ ] Vaciar cola AudioWorklet

### Fase 5: Turn Detection
- [ ] Usar `is_final` + `speech_final`
- [ ] Preparar LLM antes de utterance_end

### Fase 6: Ajustes Finos
- [ ] Chunks input: 250ms ‚Üí 100ms
- [ ] TCP_NODELAY
- [ ] Sample rate fijo

---

## üéØ PR√ìXIMOS PASOS

1. **Crear backup** del c√≥digo actual
2. **Implementar Fase 1** (TTS WebSocket + PCM) - Mayor impacto
3. **Testing** y validaci√≥n
4. **Continuar con fases siguientes**
