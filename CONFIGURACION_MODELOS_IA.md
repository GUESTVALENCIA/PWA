# ü§ñ Configuraci√≥n de Modelos de IA para Sandra

## üìä Estrategia de Prioridades

### üîµ PRODUCCI√ìN (`VERCEL_ENV=production`)

**Prioridad de modelos:**
1. **GPT-4o** (OpenAI) - Modelo principal para producci√≥n
2. **Groq (Qwen 2.5)** - Fallback r√°pido y eficiente
3. **Groq (DeepSeek R1)** - Segundo fallback
4. **Gemini 2.5-flash-lite** - √öltimo recurso

### üü¢ LOCAL (Desarrollo)

**Prioridad de modelos:**
1. **Gemini 2.5-flash-lite** - Modelo principal para desarrollo local
2. **GPT-4o** (OpenAI) - Fallback
3. **Groq (Qwen 2.5)** - Segundo fallback

---

## üîë Variables de Entorno Necesarias

### Para Producci√≥n (Prioridad Alta):

1. **OPENAI_API_KEY** (REQUERIDO para producci√≥n)
   ```
   Nombre: OPENAI_API_KEY
   Valor: sk-... (tu API key de OpenAI)
   Ambiente: Production
   ```

2. **GROQ_API_KEY** (RECOMENDADO para fallback)
   ```
   Nombre: GROQ_API_KEY
   Valor: gsk_... (tu API key de Groq)
   Ambiente: Production
   ```

### Para Desarrollo Local (Opcional):

3. **GEMINI_API_KEY** (Recomendado para local)
   ```
   Nombre: GEMINI_API_KEY
   Valor: AIzaSy... (tu API key de Gemini)
   Ambiente: Development
   ```

---

## üìã Modelos Disponibles

### OpenAI
- **Modelo**: `gpt-4o`
- **Uso**: Producci√≥n (prioridad 1)
- **Endpoint**: `https://api.openai.com/v1/chat/completions`
- **Function Calling**: ‚úÖ Soportado nativamente

### Groq (Qwen 2.5)
- **Modelo**: `qwen/qwen-2.5-72b-instruct`
- **Uso**: Producci√≥n (fallback 1)
- **Endpoint**: `https://api.groq.com/openai/v1/chat/completions`
- **Function Calling**: ‚úÖ Soportado (formato OpenAI compatible)
- **Ventajas**: Muy r√°pido, eficiente

### Groq (DeepSeek R1)
- **Modelo**: `deepseek/deepseek-r1`
- **Uso**: Producci√≥n (fallback 2)
- **Endpoint**: `https://api.groq.com/openai/v1/chat/completions`
- **Function Calling**: ‚úÖ Soportado (formato OpenAI compatible)
- **Ventajas**: Razonamiento avanzado

### Gemini 2.5-flash-lite
- **Modelo**: `gemini-2.5-flash-lite`
- **Uso**: Desarrollo local (prioridad 1) / Producci√≥n (√∫ltimo recurso)
- **Endpoint**: `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent`
- **Function Calling**: ‚ö†Ô∏è No soportado nativamente (se puede implementar con prompts)

---

## üîÑ Flujo de Decisi√≥n

```
¬øEstamos en producci√≥n?
  ‚îú‚îÄ S√ç ‚Üí ¬øTiene OPENAI_API_KEY v√°lida?
  ‚îÇ         ‚îú‚îÄ S√ç ‚Üí Usar GPT-4o
  ‚îÇ         ‚îî‚îÄ NO ‚Üí ¬øTiene GROQ_API_KEY?
  ‚îÇ                   ‚îú‚îÄ S√ç ‚Üí Usar Groq (Qwen)
  ‚îÇ                   ‚îî‚îÄ NO ‚Üí ¬øTiene GEMINI_API_KEY?
  ‚îÇ                             ‚îî‚îÄ S√ç ‚Üí Usar Gemini (√∫ltimo recurso)
  ‚îÇ
  ‚îî‚îÄ NO (Local) ‚Üí ¬øTiene GEMINI_API_KEY?
                    ‚îú‚îÄ S√ç ‚Üí Usar Gemini
                    ‚îî‚îÄ NO ‚Üí ¬øTiene OPENAI_API_KEY?
                              ‚îú‚îÄ S√ç ‚Üí Usar GPT-4o
                              ‚îî‚îÄ NO ‚Üí ¬øTiene GROQ_API_KEY?
                                        ‚îî‚îÄ S√ç ‚Üí Usar Groq (Qwen)
```

---

## üöÄ Configuraci√≥n en Vercel

### Variables Requeridas para Producci√≥n:

1. **OPENAI_API_KEY**
   - Ve a: Settings > Environment Variables
   - Nombre: `OPENAI_API_KEY`
   - Valor: `sk-...`
   - Ambiente: **Production** (y Preview si quieres)

2. **GROQ_API_KEY** (Opcional pero recomendado)
   - Nombre: `GROQ_API_KEY`
   - Valor: `gsk_...`
   - Ambiente: **Production**

3. **GEMINI_API_KEY** (Opcional, para desarrollo)
   - Nombre: `GEMINI_API_KEY`
   - Valor: `AIzaSy...`
   - Ambiente: **Development**, Preview (opcional)

---

## üìù Ejemplos de Uso

### Chat Normal (`/api/sandra/chat`)
- **Producci√≥n**: Usa GPT-4o ‚Üí Groq (Qwen) ‚Üí Gemini
- **Local**: Usa Gemini ‚Üí GPT-4o ‚Üí Groq

### Assistant con Function Calling (`/api/sandra/assistant`)
- **Producci√≥n**: Usa GPT-4o (con function calling) ‚Üí Groq (con function calling) ‚Üí Gemini (sin function calling)
- **Local**: Usa Gemini (sin function calling) ‚Üí GPT-4o ‚Üí Groq

### Llamadas Conversacionales
- **Producci√≥n**: WebSocket a MCP server ‚Üí GPT-4o para procesamiento
- **Local**: WebSocket local ‚Üí Gemini para procesamiento

---

## ‚úÖ Verificaci√≥n

Para verificar que todo funciona:

```bash
node verificar-sandra-conexiones.js
```

**Resultados esperados:**
- ‚úÖ Config endpoint funcionando
- ‚úÖ Chat usando GPT-4o en producci√≥n
- ‚úÖ Assistant usando GPT-4o en producci√≥n
- ‚úÖ Fallbacks funcionando correctamente

---

## üîß Troubleshooting

### Error: "No hay API key v√°lida configurada"
**Soluci√≥n**: Configura al menos `OPENAI_API_KEY` en Vercel para producci√≥n

### Error: "OpenAI API Error: 401"
**Soluci√≥n**: Verifica que `OPENAI_API_KEY` sea v√°lida y est√© configurada correctamente

### Error: "Groq API Error: 401"
**Soluci√≥n**: Verifica que `GROQ_API_KEY` sea v√°lida (formato: `gsk_...`)

### Usa siempre Gemini en producci√≥n
**Soluci√≥n**: Verifica que `OPENAI_API_KEY` y `GROQ_API_KEY` est√©n configuradas. El sistema solo usa Gemini como √∫ltimo recurso.

---

## üìö Referencias

- OpenAI API: https://platform.openai.com/docs
- Groq API: https://console.groq.com/docs
- Gemini API: https://ai.google.dev/docs
- Qwen Models: https://qwenlm.github.io/
- DeepSeek: https://www.deepseek.com/

