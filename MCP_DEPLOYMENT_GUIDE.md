# ğŸš€ GuÃ­a de Deployment MCP Server - Sandra IA

## ğŸ“‹ Ãndice

1. [PreparaciÃ³n](#preparaciÃ³n)
2. [Deployment Local con Docker](#deployment-local-con-docker)
3. [Deployment en Railway/Render](#deployment-en-railwayrender)
4. [IntegraciÃ³n con Vercel PWA](#integraciÃ³n-con-vercel-pwa)
5. [ConfiguraciÃ³n y Variables](#configuraciÃ³n-y-variables)
6. [VerificaciÃ³n y Testing](#verificaciÃ³n-y-testing)

---

## âœ… PreparaciÃ³n

### Requisitos

- âœ… Node.js 18+
- âœ… Docker (para deployment containerizado)
- âœ… Variables de entorno configuradas
- âœ… Cuenta en Railway/Render (opcional, para deployment cloud)

### Estructura del Proyecto

```
mcp-server/
â”œâ”€â”€ server.js              # Servidor principal
â”œâ”€â”€ router/
â”‚   â””â”€â”€ mcp-router.js     # Gateway de control
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chat.js           # Servicio de chat
â”‚   â”œâ”€â”€ voice.js          # Servicio de voz
â”‚   â”œâ”€â”€ vision.js         # Servicio de visiÃ³n
â”‚   â”œâ”€â”€ commands.js       # Servicio de comandos
â”‚   â””â”€â”€ scheduler.js      # Servicio de scheduler
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ package.json
â””â”€â”€ .env.example
```

---

## ğŸ³ Deployment Local con Docker

### Paso 1: Preparar Variables de Entorno

```bash
cd mcp-server
cp .env.example .env
# Editar .env con tus claves API
```

### Paso 2: Construir y Ejecutar

```bash
# OpciÃ³n A: Docker Compose (Recomendado)
docker-compose up -d

# OpciÃ³n B: Docker directo
docker build -t sandra-mcp-server .
docker run -d -p 4042:4042 --env-file .env --name sandra-mcp sandra-mcp-server
```

### Paso 3: Verificar

```bash
# Health check
curl http://localhost:4042/health

# Status
curl http://localhost:4042/mcp-router/status
```

---

## â˜ï¸ Deployment en Railway/Render

### Railway

1. **Crear proyecto nuevo** en Railway
2. **Conectar repositorio** GitHub
3. **Configurar variables de entorno** en Railway Dashboard
4. **Railway detectarÃ¡ automÃ¡ticamente** el Dockerfile
5. **Deploy automÃ¡tico** en cada push

**Railway detectarÃ¡:**
- Puerto: 4042 (configurar en Railway)
- Health check: `/health`
- Build: Dockerfile

### Render

1. **Nuevo Web Service** en Render
2. **Conectar repositorio** GitHub
3. **ConfiguraciÃ³n:**
   - Build Command: `docker build -t sandra-mcp-server .`
   - Start Command: `docker run -p $PORT:4042 sandra-mcp-server`
   - Environment: Variables de entorno
4. **Deploy**

### Variables de Entorno Necesarias

```
MCP_PORT=4042
MCP_HOST=0.0.0.0

# API Keys
DEEPSEEK_API_KEY=...
QWEN_API_KEY=...
OPENAI_API_KEY=...
GEMINI_API_KEY=...
CARTESIA_API_KEY=...
CARTESIA_VOICE_ID=...
DEEPGRAM_API_KEY=...
BRIDGEDATA_API_KEY=...
NEON_DB_URL=...
```

---

## ğŸ”— IntegraciÃ³n con Vercel PWA

### Paso 1: Configurar Variable en Vercel

En Vercel Dashboard > Settings > Environment Variables:

```
MCP_SERVER_URL=https://tu-mcp-server.railway.app
```

O si es Render:

```
MCP_SERVER_URL=https://sandra-mcp-server.onrender.com
```

### Paso 2: Actualizar Endpoints en Vercel

Los endpoints `/api/sandra/*` automÃ¡ticamente intentarÃ¡n usar MCP si estÃ¡ disponible.

### Paso 3: Verificar ConexiÃ³n

```bash
# Desde Vercel (serverless function)
curl https://tu-pwa.vercel.app/api/sandra/mcp/status
```

---

## âš™ï¸ ConfiguraciÃ³n y Variables

### Variables CrÃ­ticas

| Variable | DescripciÃ³n | Requerida |
|----------|-------------|-----------|
| `MCP_PORT` | Puerto del servidor | SÃ­ |
| `DEEPSEEK_API_KEY` | API Key DeepSeek | Recomendada |
| `OPENAI_API_KEY` | API Key OpenAI (fallback) | SÃ­ |
| `CARTESIA_API_KEY` | API Key Cartesia (TTS) | SÃ­ |
| `DEEPGRAM_API_KEY` | API Key Deepgram (STT) | SÃ­ |

### ConfiguraciÃ³n de Modelos

El sistema tiene fallback automÃ¡tico:

1. **Primary**: DeepSeek R1
2. **Secondary**: Qwen
3. **Fallback**: GPT-4o (OpenAI)

---

## âœ… VerificaciÃ³n y Testing

### Health Check

```bash
curl http://tu-mcp-server/health
```

**Respuesta esperada:**
```json
{
  "status": "ok",
  "timestamp": "2025-01-15T12:00:00.000Z",
  "services": {
    "chat": true,
    "voice": true,
    "vision": true,
    "commands": true,
    "scheduler": true
  }
}
```

### Probar Chat

```bash
curl -X POST http://tu-mcp-server/mcp-router/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hola Sandra",
    "context": "Eres Sandra IA, asistente de GuestsValencia"
  }'
```

### Probar Voice (TTS)

```bash
curl -X POST http://tu-mcp-server/mcp-router/voice/tts \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hola, soy Sandra",
    "voiceId": "a34aec03-0f17-4fff-903f-d9458a8a92a6"
  }'
```

### WebSocket Test

```javascript
const ws = new WebSocket('ws://tu-mcp-server');
ws.on('open', () => {
  ws.send(JSON.stringify({
    service: 'chat',
    action: 'message',
    payload: {
      message: 'Hola Sandra',
      options: {}
    }
  }));
});

ws.on('message', (data) => {
  console.log('Respuesta:', JSON.parse(data));
});
```

---

## ğŸ”„ Flujo Completo

```
PWA (Vercel) 
  â†“
/api/sandra/chat.js (Serverless Function)
  â†“
MCP Proxy (/api/sandra/mcp-proxy.js)
  â†“
MCP Server (Railway/Render)
  â†“
Chat Service â†’ DeepSeek/Qwen/GPT-4o
  â†“
Respuesta â†’ PWA
```

---

## ğŸ› Troubleshooting

### MCP Server no responde

1. Verificar que el servidor estÃ¡ corriendo
2. Verificar variables de entorno
3. Revisar logs: `docker logs sandra-mcp`

### Error de conexiÃ³n desde Vercel

1. Verificar `MCP_SERVER_URL` en Vercel
2. Verificar que MCP Server acepta conexiones externas
3. Verificar CORS en MCP Server

### Modelos no responden

1. Verificar API keys en `.env`
2. Revisar fallback automÃ¡tico en logs
3. Verificar lÃ­mites de rate limiting

---

## ğŸ“Š Monitoreo

### Logs en Docker

```bash
docker logs -f sandra-mcp
```

### Snapshots

El scheduler crea snapshots automÃ¡ticamente. Ver en:

```bash
ls mcp-server/snapshots/
```

---

**âœ¨ MCP Server listo para orquestar Sandra IA en producciÃ³n!**

